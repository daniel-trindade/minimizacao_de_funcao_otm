%%%%%%%%%%%% STRUCTURE %%%%%%%%%%%%%%%
\documentclass[a4paper,12pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{lmodern}
\usepackage{setspace}
\usepackage{float}
\usepackage[top=2cm, bottom=2cm, left=2cm, right=2cm]{geometry}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%% PAGES STYLE %%%%%%%%%
\usepackage{fancyhdr}
\fancypagestyle{main}{
\renewcommand{\headrulewidth}{0pt}
\fancyhead[RO]{\thepage}
\fancyfoot[CO]{}
}
%%%%%%%%%INSERÇÃO DE CÓDIGO%%%%%%%%%%%%%%%

\usepackage{listings}
\usepackage{xcolor}

\lstset{
	basicstyle=\ttfamily\small,
	keywordstyle=\color{blue},
	commentstyle=\color{gray},
	stringstyle=\color{green!50!black},
	breaklines=true,
	frame=single,
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{subfig}
\usepackage{mathptmx}
\usepackage{changepage}
%\usepackage[alf]{abntex2cite}

%%%%%%%%%%% PDF METADATA %%%%%%%%%%%%%
\usepackage[ pdftitle={RELATÓRIO DE ANALISE DE MINIMIZAÇÃO DE FUNÇÕES POR ALGORITMOS GENETICOS E ENXAME DE PARTICULAS},
pdfsubject={MINIMIZAÇÃO DE FUNÇÕES},
pdfkeywords={minimização, algoritmos, geneticos, enxame, particulas},
hidelinks]{hyperref}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\onehalfspacing

\thispagestyle{empty}

\setcounter{page}{1}

%%%%%%%%%%%% LOGOS %%%%%%%%%%%%%%%%%%%

\begin{figure}[!ht]

\centering

\subfloat{
\includegraphics[width=2.7cm]{imgs/UFRN.pdf}
\label{UFRN Logo}
}
\hspace{11.09cm}
\subfloat{
\includegraphics[width=2.4cm]{imgs/DCA.pdf}
\label{DCA Logo}
}

%\caption{}
\label{Logos}

\end{figure}

%%%%%%%%%%%%%%% CAPA %%%%%%%%%%%%%%%%%

\vspace{-1cm}

\begin{center}
{\bf{\normalsize UNIVERSIDADE FEDERAL DO RIO GRANDE DO NORTE\\
DEPARTAMENTO DE ENGENHARIA DE COMPUTAÇÃO E AUTOMAÇÃO\\
CURSO DE ENGENHARIA DE COMPUTAÇÃO\\
OTIMIZAÇÃO DE SISTEMAS
}}


\vspace{3.6cm}

{\bf{\large RELATÓRIO DO TRABALHO DE MINIMIZAÇÃO DE FUNÇÕES\\
ATRAVÉS DE ALGORITMOS GENÉTICOS E ENXAME DE PARTÍCULAS\\
}}
\vspace{1.5cm}


\vspace{5.6cm}



\begin{flushright}
\begin{normalsize}
DANIEL BRUNO TRINDADE DA SILVA - 20230093910\\

\end{normalsize}
\end{flushright}


\vspace{6.5cm}

{\large Natal-RN\\
2025.2}
\end{center}

\newpage

%%%%%%%%%%%%%%%  RESUMO %%%%%%%%%%%%%%

\thispagestyle{empty}

\begin{center}
{\large \textbf{RESUMO}}
\end{center}

\vspace{3cm}

\begin{flushleft}

Este trabalho apresenta a implementação e a análise comparativa de duas metaheurísticas de otimização, o Algoritmo Genético (AG) e a Otimização por Enxame de Partículas (PSO), aplicadas à minimização da função objetivo multimodal $W_{29} + W_1$. O objetivo principal consistiu em avaliar não apenas a capacidade de convergência para o mínimo global, mas também o custo computacional associado a cada abordagem. A metodologia envolveu o desenvolvimento dos algoritmos em linguagem Python e a execução de um planejamento fatorial de experimentos, variando-se parâmetros críticos como tamanho da população, taxas de cruzamento e mutação para o AG, e coeficientes de aceleração e tamanho do enxame para o PSO. A análise estatística baseou-se em métricas consolidadas de 10 execuções independentes para cada cenário de teste. Os resultados demonstraram que o AG obteve sua melhor eficiência com uma população de 50 indivíduos, enquanto o PSO exigiu uma configuração comportamental "individualista" ($c_1 > c_2$) para superar mínimos locais. Conclui-se que houve uma distinção clara de desempenho: o PSO mostrou-se superior na precisão absoluta da solução final, atingindo os menores valores de função, enquanto o AG destacou-se pela eficiência, alcançando resultados competitivos com um custo computacional (número de avaliações da função) significativamente inferior.

\end{flushleft}

\vspace{1.5cm}

\textbf{Palavras-chave:}Otimização Heurística. Algoritmos Genéticos. Enxame de Partículas (PSO). Custo Computacional. Minimização de Funções.

\newpage

%%%%%%%%%%%%%%% SUMÁRIO %%%%%%%%%%%%%%

\thispagestyle{empty}

\begin{center}
\tableofcontents
\end{center}

\newpage

%%%%%%%%%%%%%%% INTRODUÇÃO %%%%%%%%%%%

\thispagestyle{main}

\section{INTRODUÇÃO}

\hspace{4ex}A otimização de funções matemáticas complexas é um desafio central em diversas áreas da engenharia. Quando o espaço de busca é vasto e a função objetivo apresenta múltiplos mínimos locais, métodos analíticos tradicionais tornam-se ineficientes. Nesse contexto, algoritmos metaheurísticos inspirados na natureza destacam-se como soluções robustas para encontrar o ótimo global.

O presente trabalho tem como objetivo implementar e analisar o desempenho de duas das principais técnicas de computação evolucionária e inteligência: o Algoritmo Genético (AG) e a Otimização por Enxame de Partículas (PSO - \textit{Particle Swarm Optimization})1. A meta é minimizar a função objetivo composta definida pela combinação $W29 + W1$, conforme designado na especificação do projeto.

Para além da simples obtenção do mínimo global, este estudo foca na análise comparativa do custo computacional de cada abordagem. Conforme os requisitos propostos, foram mensuradas a quantidade de avaliações da função objetivo e o número de operações aritméticas (multiplicações e divisões) necessárias para a convergência. A estabilidade dos algoritmos também foi avaliada estatisticamente, verificando a taxa de sucesso na convergência em múltiplas execuções independentes.

O desenvolvimento foi realizado utilizando a linguagem Python, escolhida pela sua capacidade de prototipagem rápida e bibliotecas de manipulação numérica, permitindo uma instrumentação precisa do código para a coleta das métricas de desempenho exigidas.

\newpage

%%%%%%%%%% REFERENCIAL TEÓRICO %%%%%%%

\thispagestyle{main}

\section{REFERENCIAL TEÓRICO}

\hspace{4ex}A resolução de problemas de otimização não-linear, especialmente aqueles com múltiplas variáveis e ótimos locais, frequentemente excede a capacidade de métodos analíticos tradicionais baseados em gradiente. Nestes cenários, algoritmos metaheurísticos inspirados na natureza demonstram eficácia superior na exploração do espaço de busca global.

\subsection{Algoritmos Genéticos (AG)} 

\hspace{4ex}Desenvolvidos inicialmente por John Holland na década de 1960 e popularizados por David Goldberg, os Algoritmos Genéticos são técnicas de busca estocástica baseadas nos princípios da seleção natural e genética de populações (HOLLAND, 1975).

O funcionamento do AG baseia-se na evolução de uma população de indivíduos (candidatos à solução) ao longo de gerações. A aptidão (\textit{fitness}) de cada indivíduo determina sua probabilidade de sobrevivência e reprodução, seguindo a premissa Darwiniana de que os mais aptos tendem a propagar suas características (GOLDBERG, 1989).

Os principais operadores que conduzem a busca são:

\begin{itemize}
	\item \textbf{Seleção:} Mecanismo que escolhe os pais para a reprodução. Neste trabalho, utiliza-se o método da Roleta, onde a probabilidade de seleção de um indivíduo é proporcional à sua aptidão relativa na população.
	\item \textbf{Cruzamento (\textit{Crossover}):} Processo de recombinação genética onde dois pais trocam informações para gerar descendentes. Para problemas com variáveis contínuas (codificação real), utilizam-se operadores aritméticos ou mistos, como o BLX-$\alpha$, que permitem explorar o espaço entre os pais (HERRERA et al., 1998).
	\item \textbf{Mutação:} Operador responsável por manter a diversidade genética da população, introduzindo pequenas perturbações aleatórias nos genes, evitando a convergência prematura para mínimos locais (MITCHELL, 1998).
\end{itemize}

\subsection{Otimização por Enxame de Partículas (PSO)}

A Otimização por Enxame de Partículas é um algoritmo metaheurístico proposto por Kennedy e Eberhart em 1995, inspirado no comportamento social de organismos simples, como bandos de pássaros ou cardumes de peixes (KENNEDY; EBERHART, 1995).

Diferente do AG, o PSO não utiliza operadores de evolução (como cruzamento ou mutação). Em vez disso, mantém uma população de partículas que "voam" pelo hiperespaço de busca. Cada partícula ajusta sua trajetória baseando-se em duas experiências:

\begin{enumerate}
	\item Cognitiva ($p_{best}$): A melhor posição encontrada pela própria partícula até o momento.
	\item Social ($g_{best}$): A melhor posição encontrada por qualquer partícula do enxame (vizinhança).
\end{enumerate}

Matematicamente, a velocidade ($v$) e a posição ($x$) de cada partícula $i$ são atualizadas pelas equações:

$$v_{i}(t+1) = w \cdot v_{i}(t) + c_1 \cdot r_1 \cdot (p_{best} - x_{i}(t)) + c_2 \cdot r_2 \cdot (g_{best} - x_{i}(t))$$$$x_{i}(t+1) = x_{i}(t) + v_{i}(t+1)$$

Onde $c_1$ e $c_2$ são coeficientes de aceleração (cognitivo e social) e $r_1, r_2$ são valores aleatórios. O parâmetro $w$ (peso de inércia), introduzido posteriormente por Shi e Eberhart (1998), é crucial para controlar o balanço entre a exploração global (\textit{exploration}) e o refinamento local (\textit{exploitation}).


\newpage

%%%%%%%%%% METODOLOGIA %%%%%%%%%%%%%%%

\thispagestyle{main}

\section{METODOLOGIA}


\hspace{4ex}Esta seção detalha a abordagem computacional adotada para a minimização da função objetivo $W_{29} + W_1$. Os algoritmos foram implementados em linguagem Python, utilizando a biblioteca NumPy para operações vetoriais de alto desempenho e Matplotlib para a geração gráfica dos resultados.

\begin{figure}[h!]
	\centering
	\includegraphics[width=0.5\textwidth]{./imgs/w29+w1.png}
	\caption{Função $W29 + W1$.}
	\label{fig:W29 + W1}
\end{figure}

Para garantir a reprodutibilidade e a análise comparativa exigida, o código foi instrumentado com contadores globais de operações aritméticas, permitindo a mensuração exata do custo computacional independente do hardware utilizado.

\subsection{Definição da Função Objetivo}
\hspace{4ex}A função a ser minimizada é a composição $f(x, y) = W_{29}(x, y) + W_1(x, y)$, definida no domínio de busca $x, y \in [-500, 500]$. A implementação computacional da função respeitou rigorosamente a precedência de operadores e as funções auxiliares (como $z$, $r$, $r1$ e $rd$) descritas na especificação do problema, garantindo a fidelidade matemática ao modelo original em Scilab.

\subsection{Implementação do Algoritmo Genético (AG)}

\hspace{4ex}O Algoritmo Genético foi configurado para operar com codificação real (ponto flutuante), onde cada gene do cromossomo corresponde diretamente ao valor de uma variável de decisão ($x$ ou $y$). Esta abordagem evita a perda de precisão associada à conversão binária em domínios contínuos.

A estrutura do Algoritmo segue os seguinte parâmetros e operadores:

\begin{itemize}
	\item \textbf{População}: A escolha do tamanho da população nos leva a um \textit{trade-off} entre o quanto seremos capazes de explorar (para valores pequenos) da função e o custo computacional que a simulação vai demandar (para populações grandes). Para as simulações realizadas foram escolhidos os seguintes valores 20, 50, 100 e 200.
	
	\item \textbf{Seleção por Roleta}: Foi adotado o método da Roleta (Roulette Wheel Selection), conforme requisito do projeto. Para adequação ao problema de minimização, a aptidão (fitness) de cada indivíduo foi normalizada inversamente, de modo que menores valores da função objetivo resultassem em maiores fatias na roleta virtual, ou seja, maior probabilidade de reprodução.
	
	\item \textbf{Cruzamento (Crossover):} Utilizou-se o operador BLX-$\alpha$ (Blend Crossover) com $\alpha = 0.5$. Este operador permite que os filhos sejam gerados em um intervalo que excede ligeiramente a distância entre os pais, promovendo a exploração de novas regiões do espaço de busca. Com relação a taxa de Cruzamento, a variamos para ver como ela influencia nos resultados obtidos, os valores assumidos foram de 50\%, 70\%, 90\% e 100\%.
	
	\item \textbf{Mutação:} Tal qual os demais parâmetros realizamos testes com diferentes taxas de mutação, a saber 1\%, 5\% 10\% e 20\%. Quando ativada, o gene é substituído por um novo valor aleatório dentro do domínio, garantindo a diversidade genética e evitando estagnação em mínimos locais.
	
	\item \textbf{Critério de Parada:} O algoritmo encerra-se após 200 gerações ou caso não haja melhoria significativa (tolerância de $10^{-6}$) na melhor solução global por 20 gerações consecutivas.
\end{itemize}

\subsection{Implementação do Enxame de Partículas (PSO)}

\hspace{4ex}O método PSO foi implementado utilizando uma topologia global, onde todas as partículas têm acesso à melhor posição encontrada pelo enxame ($g_{best}$).

A estrutura do Algoritmo segue os seguinte parâmetros e operadores:

\begin{itemize}
	\item \textbf{Enxame:} No PSO, o tamanho do enxame (número de partículas) é o parâmetro que define a cobertura espacial inicial. Esse parâmetro traz consigo o mesmo \textit{trade-off} que o tamanho da população no AG: Custo computacional \textit{vs} Área de cobertura. Para nossas simulações utilizamos 10, 30, 50 e 100 partículas;
	
	\item \textbf{Coeficientes de Aceleração:}Os parâmetros $c_1$ (Cognitivo) e $c_2$ (Social) definem a "personalidade" do enxame. Eles controlam o cabo de guerra entre a "insistência" da partícula em voltar para onde ela já encontrou bons resultados ($c_1$) e a "inveja" de ir para onde o vizinho está se dando bem ($c_2$). Esses parâmetros foram testados da seguinte forma:
		\begin{itemize}
			\item \textbf{Enxame Equilibrado}: $c_1 = 2.0$ e $c_2 = 2.0$
			\item \textbf{Enxame Individualista:} $c_1 = 3.5$ e $c_2 = 0.5$
			\item \textbf{Enxame Social:} $c_1 = 0.5$ e $c_2 = 3.5$
			\item \textbf{Enxame Letárgico:} $c_1 = 0.5$ e $c_2 = 0.5$
		\end{itemize}
	 
	
	\item \textbf{Peso de Inércia ($w$):} Implementou-se um mecanismo de Inércia Dinâmica Linearmente Decrescente, variando de $w_{max} = 0.9$ (início da busca, favorecendo exploração) até $w_{min} = 0.4$ (fim da busca, favorecendo refinamento/explotação).
	
	\item \textbf{Critério de Parada:} Máximo de 100 iterações ou estagnação da convergência por 20 iterações consecutivas.
\end{itemize}

\subsection{Simulações}

\hspace{4ex}Devido à natureza estocástica dos algoritmos metaheurísticos, onde operadores probabilísticos (como a inicialização aleatória, a roleta no AG ou os vetores randômicos no PSO) influenciam diretamente o caminho da busca, uma única execução não é suficiente para atestar a qualidade de uma solução.

Para garantir a validade estatística dos resultados e mitigar a influência da aleatoriedade, adotou-se o seguinte protocolo experimental:

\begin{itemize}
	\item \textbf{Planejamento Fatorial:} Foram definidos cenários de teste distintos para cada algoritmo (conforme já detalhado acima), variando-se sistematicamente os parâmetros de controle ($C_1, C_2, N$ para o PSO e Tamanho, Cruzamento, Mutação para o AG).
	
	\item \textbf{Repetições Independentes:} Para cada um desses conjuntos de parâmetros, foram realizadas 10 simulações independentes. A cada nova execução, a semente aleatória (\textit{random seed}) foi alterada, garantindo que a população/enxame iniciasse em posições distintas do espaço de busca.
	
	\item \textbf{Consolidação dos Dados:} Ao final das 10 execuções de um cenário, as métricas de desempenho (melhor valor encontrado, número de avaliações e iteração de convergência) foram computadas para extração da Média e do Desvio Padrão.
\end{itemize}


Desta forma, a análise de desempenho apresentada neste trabalho baseia-se no comportamento médio e na estabilidade (robustez) do algoritmo frente a diferentes condições iniciais, totalizando 160 execuções computacionais (90 para o AG e 70 para o PSO).


\newpage

%%%%%%%%%% RESULTADOS %%%%%%%%%%%%%%%

\thispagestyle{main}

\section{RESULTADOS}


\hspace{4ex}Nesta seção, são apresentados e discutidos os resultados experimentais obtidos a partir da aplicação dos algoritmos Genético (AG) e Enxame de Partículas (PSO) na minimização da função objetivo $W_{29} + W_1$. A análise subsequente foca na avaliação comparativa da robustez (capacidade de atingir o mínimo global), na velocidade de convergência e no custo computacional (mensurado pelo número de avaliações da função e operações aritméticas) de cada abordagem

\subsection{Algoritmo Genético (AG)}

\hspace{4ex}Inicialmente fixamos os valores dos parâmetros Mutação e Cruzamento em 5\% e 70\% respectivamente e então variamos o tamanho da população. Assim tivemos os seguintes resultados

\subsubsection{População=20 Mutação=0.05 Cruzamento=0.7}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=20 mult=0.05 cruz=0.7.png}
		\caption{Sumário de Desempenho}
		\label{fig:img1}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=20 mult=0.05 cruz=0.7 Barras.png}
		\caption{Estatísticas}
		\label{fig:img2}
	\end{minipage}
	
\end{figure}

\subsubsection{População=50 Mutação=0.05 Cruzamento=0.7}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=0.7.png}
		\caption{Sumário de Desempenho}
		\label{fig:img3}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=0.7 Barras.png}
		\caption{Estatísticas}
		\label{fig:img4}
	\end{minipage}
	
\end{figure}

\subsubsection{População=100 Mutação=0.05 Cruzamento=0.7}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=100 mult=0.05 cruz=0.7.png}
		\caption{Sumário de Desempenho}
		\label{fig:img5}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=100 mult=0.05 cruz=0.7 Barras.png}
		\caption{Estatísticas}
		\label{fig:img6}
	\end{minipage}
	
\end{figure}

\subsubsection{População=200 Mutação=0.05 Cruzamento=0.7}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=200 mult=0.05 cruz=0.7.png}
		\caption{Sumário de Desempenho}
		\label{fig:img7}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=200 mult=0.05 cruz=0.7 Barras.png}
		\caption{Estatísticas}
		\label{fig:img8}
	\end{minipage}
	
\end{figure}

\hspace{4ex}Agora fixamos a População em 50 pois foi o valor que melhor desempenhou ao minimizar a função com menor custo computacional e fixamos o valor de cruzamento em 70\%.

\subsubsection{População=50 Mutação=0.01 Cruzamento=0.7}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.01 cruz=0.7.png}
		\caption{Sumário de Desempenho}
		\label{fig:img9}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.01 cruz=0.7 Barras.png}
		\caption{Estatísticas}
		\label{fig:img10}
	\end{minipage}
	
\end{figure}

\subsubsection{População=50 Mutação=0.05 Cruzamento=0.7}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=0.7.png}
		\caption{Sumário de Desempenho}
		\label{fig:img11}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=0.7 Barras.png}
		\caption{Estatísticas}
		\label{fig:img12}
	\end{minipage}
	
\end{figure}

\subsubsection{População=50 Mutação=0.1 Cruzamento=0.7}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.1 cruz=0.7.png}
		\caption{Sumário de Desempenho}
		\label{fig:img13}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.1 cruz=0.7 Barras.png}
		\caption{Estatísticas}
		\label{fig:img14}
	\end{minipage}
	
\end{figure}

\subsubsection{População=50 Mutação=0.2 Cruzamento=0.7}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.2 cruz=0.7.png}
		\caption{Sumário de Desempenho}
		\label{fig:img15}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.2 cruz=0.7 Barras.png}
		\caption{Estatísticas}
		\label{fig:img16}
	\end{minipage}
	
\end{figure}

\hspace{4ex}Agora manteremos fixos os valores de População em 50 e mutação em 0,05 a vamos analisar a dinâmica de mudança no parâmetro de cruzamento

\subsubsection{População=50 Mutação=0.05 Cruzamento=0.5}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=0.5.png}
		\caption{Sumário de Desempenho}
		\label{fig:img17}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=0.5 Barras.png}
		\caption{Estatísticas}
		\label{fig:img18}
	\end{minipage}
	
\end{figure}

\subsubsection{População=50 Mutação=0.05 Cruzamento=0.7}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=0.7.png}
		\caption{Sumário de Desempenho}
		\label{fig:img19}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=0.7 Barras.png}
		\caption{Estatísticas}
		\label{fig:img20}
	\end{minipage}
	
\end{figure}

\subsubsection{População=50 Mutação=0.05 Cruzamento=1.0}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=1.0.png}
		\caption{Sumário de Desempenho}
		\label{fig:img21}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_AG/pop=50 mult=0.05 cruz=1.0 Barras.png}
		\caption{Estatísticas}
		\label{fig:img22}
	\end{minipage}
	
\end{figure}

\subsubsection{Tabela de consolidação dos dados levantados:}

\begin{table}[H]
	\centering
	\begin{tabular}{lrrrrrrr}
		\hline
		\textbf{N} & 
		\textbf{Configuração} & 
		\textbf{Total de Cálculos} &
		\textbf{Geração} &
		\textbf{Melhor Valor} \\
		\hline
		1 &  Pop=20 Mut=0,05 Cruz=0,7   & 17293  & 41,3 & -2532,56 \\
		2 &  Pop=50 Mut=0,1 Cruz=0,7    & 62085  & 51,2 & -3038,14 \\
		3 &  Pop=50 Mut=0,01 Cruz=0,7   & 43894  & 42,2 & -2689,25 \\
		4 &  Pop=50 Mut=0,2 Cruz=0,7    & 81928  & 61   & -3180,84 \\
		5 &  Pop=50 Mut=0,05 Cruz=0,5   & 59177  & 49,9 & -2981,64 \\
		6 &  Pop=50 Mut=0,05 Cruz=0,7   & 37015  & 38,8 & -3135,21 \\
		7 &  Pop=50 Mut=0,05 Cruz=1,0   & 27290  & 33,9 & -2854,92 \\
		8 &  Pop=100 Mut=0,05 Cruz=0,7  & 112639 & 48,6 & -3225,81 \\
		9 &  Pop=200 Mut=0,05 Cruz=0,7  & 135632 & 37,5 & -3028,88 \\
		\hline
	\end{tabular}
	\caption{Resultados dos experimentos do Algoritmo Genético}
\end{table}

\hspace{4ex} De posse dessas informações podemos realizar algumas analises:

\begin{enumerate}
	\item \textbf{Análise do Tamanho da População} (Trade-off Custo x Qualidade)
	Comparando as linhas onde Mut=0,05 e Cruz=0,7 (linhas 1, 6, 8 e 9), vemos claramente o impacto da escala:
	
	\begin{itemize}
		\item \textbf{População Pequena (20):} Teve o menor custo computacional (17.293 cálculos), mas o pior resultado de todos (-2.532). Isso é um sinal clássico de Convergência Prematura. Havia pouca diversidade genética, e o algoritmo ficou preso em um mínimo local ruim rapidamente.
		
		\item \textbf{População Média (50):} Atingiu um valor excelente (-3.135) com um custo muito baixo (37.015). Parece ser o "ponto ideal" (\textit{sweet spot}) de eficiência.
		
		\item \textbf{População Grande (100):} Encontrou o melhor valor absoluto da tabela (-3.225,81). No entanto, o custo computacional saltou para 112.639 (3x mais que a população de 50).
		
		\item \textbf{População Muito Grande (200):} Aqui vemos o efeito de retornos decrescentes. O custo foi o maior de todos (135.632), mas o resultado (-3.028) foi pior que o da população de 100 e até pior que a de 50. Isso sugere que apenas aumentar a população cegamente não garante melhoria e desperdiça recursos.
	\end{itemize}
	
	\item \textbf{Influência da Taxa de Mutação} (Estabilidade vs. Exploração)
	Focando nas linhas com Pop=50 e Cruz=0,7 (linhas 2, 3, 4 e 6):
	\begin{itemize}
		\item \textbf{Mutação Baixa (0,01):} Resultado fraco (-2.689). O algoritmo provavelmente perdeu diversidade muito rápido e estagnou.
		
		\item \textbf{Mutação Moderada (0,05):} Resultado muito bom (-3.135) com o menor custo deste grupo (37k). Convergiu rápido (geração 38,8).
		
		\item \textbf{Mutação Alta (0,1):} O "Vale" de Desempenho: É curioso notar que a taxa de 20\% (0,2) obteve um resultado melhor (-3.180) que a de 10\% (-3.038)
		
		\item \textbf{Mutação Alta (0,2):} Surpreendentemente, obteve um resultado muito bom (-3.180), superando a mutação moderada em qualidade. Porém, observe o custo e a geração: o custo dobrou (81.928) e a convergência foi a mais tardia da tabela (geração 61).
	\end{itemize}
	
	\item \textbf{Impacto da Taxa de Cruzamento} Comparando as linhas 5, 6 e 7 (fixando Pop=50 e Mut=0,05):
	
	\begin{itemize}
		\item \textbf{Cruzamento 0,5 (50\%):} Resultado mediano (-2.981) com custo alto (59k). Preservar demais os pais não foi benéfico.
		
		\item \textbf{Cruzamento 0,7 (70\%):} Foi o vencedor claro neste cenário (-3.135).
		
		\item \textbf{Cruzamento 1,0 (100\%):} Teve a convergência mais rápida da tabela (geração 33,9) e custo baixo, mas o resultado foi ruim (-2.854).
	\end{itemize}
\end{enumerate}

\subsection{Enxame de Partículas (PSO)}

\hspace{4ex}Para iniciar a analise do PSO começamos fixando os valores dos coeficientes de aceleração Cognitivo ($C_1$) e Social ($C_2$) em 2. Lembrando que nosso o de inercia é dinâmico começando baixo e conforme as iterações vão aumentando o valor de inercia também aumenta.

\subsubsection{Partículas=10 Cognitivo ($C_1$)=2 Social ($C_2$)=2}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=10 c1=2 c2=2.png}
		\caption{Sumário de Desempenho}
		\label{fig:img23}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=10 c1=2 c2=2 barras .png}
		\caption{Estatísticas}
		\label{fig:img24}
	\end{minipage}
	
\end{figure}

\subsubsection{Partículas=30 Cognitivo ($C_1$)=2 Social ($C_2$)=2}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=2 c2=2.png}
		\caption{Sumário de Desempenho}
		\label{fig:img25}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=2 c2=2 barras .png}
		\caption{Estatísticas}
		\label{fig:img26}
	\end{minipage}
	
\end{figure}

\subsubsection{Partículas=50 Cognitivo ($C_1$)=2 Social ($C_2$)=2}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=50 c1=2 c2=2.png}
		\caption{Sumário de Desempenho}
		\label{fig:img27}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=50 c1=2 c2=2 barras .png}
		\caption{Estatísticas}
		\label{fig:img28}
	\end{minipage}
	
\end{figure}

\subsubsection{Partículas=100 Cognitivo ($C_1$)=2 Social ($C_2$)=2}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=100 c1=2 c2=2.png}
		\caption{Sumário de Desempenho}
		\label{fig:img29}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=100 c1=2 c2=2 barras .png}
		\caption{Estatísticas}
		\label{fig:img30}
	\end{minipage}
	
\end{figure}

\hspace{4ex}Agora fixamos a quantidade de partículas em 30 e passaremos a analisar os parâmetros de aceleração Cognitivo ($C_1$) e Social ($C_2$).

\subsubsection{Partículas=30 Cognitivo ($C_1$)=0.5 Social ($C_2$)=0.5}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=0.5 c2=0.5.png}
		\caption{Sumário de Desempenho}
		\label{fig:img31}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=0.5 c2=0.5 barras .png}
		\caption{Estatísticas}
		\label{fig:img32}
	\end{minipage}
	
\end{figure}


\subsubsection{Partículas=30 Cognitivo ($C_1$)=2 Social ($C_2$)=2}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=2 c2=2.png}
		\caption{Sumário de Desempenho}
		\label{fig:img33}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=2 c2=2 barras .png}
		\caption{Estatísticas}
		\label{fig:img34}
	\end{minipage}
	
\end{figure}

\subsubsection{Partículas=30 Cognitivo ($C_1$)=3.5 Social ($C_2$)=0.5}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=3.5 c2=0.5.png}
		\caption{Sumário de Desempenho}
		\label{fig:img35}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=3.5 c2=0.5 barras .png}
		\caption{Estatísticas}
		\label{fig:img36}
	\end{minipage}
	
\end{figure}


\subsubsection{Partículas=30 Cognitivo ($C_1$)=0.5 Social ($C_2$)=3.5}

\begin{figure}[H]
	\centering
	
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=0.5 c2=3.5.png}
		\caption{Sumário de Desempenho}
		\label{fig:img37}
	\end{minipage}
	\hfill
	\begin{minipage}{0.48\textwidth}
		\centering
		\includegraphics[width=\textwidth]{./imgs/analise_PSO/part=30 c1=0.5 c2=3.5 barras .png}
		\caption{Estatísticas}
		\label{fig:img38}
	\end{minipage}
	
\end{figure}

\subsubsection{Tabela de consolidação dos dados levantados:}

\begin{table}[H]
	\centering
	\begin{tabular}{lrrrr}
		\hline
		\textbf{N} & 
		\textbf{Configuração} & 
		\textbf{Total de Cálculos} &
		\textbf{Geração} &
		\textbf{Melhor Valor} \\
		\hline
		1 &  part=10 c1=2 c=2        & 32329  & 76,1 & -2607,3  \\
		2 &  part=30 c1=0.5 c=0.5    & 106220 & 79,9 & -2999,67 \\
		3 &  part=30 c1=0.5 c=3.5    & 89586  & 76,3 & -2987,84 \\
		4 &  part=30 c1=2 c=2        & 106559 & 84,8 & -2987,85 \\
		5 &  part=30 c1=3.5 c=0.5    & 95082  & 78,4 & -3307,46 \\
		6 &  part=50 c1=2 c=2        & 183801 & 95,0 & -3308,26 \\
		7 &  part=100 c1=2 c=2       & 345454 & 81,0 & -3148,02 \\
		\hline
	\end{tabular}
\end{table}

\hspace{4ex}Diferente do AG, onde a população maior ajudou até certo ponto, aqui vemos que a personalidade das partículas ($c_1$ vs $c_2$) teve um impacto mais decisivo na eficiência do que o tamanho bruto do enxame.

\begin{enumerate}
	
	\item \textbf{Análise do Tamanho do Enxame} Comparando as linhas onde mantivemos o padrão $c_1=2, c_2=2$ (linhas 1, 4, 6 e 7):
	\begin{itemize}
		\item \textbf{Enxame Pequeno (10 - Linha 1):}Resultado muito fraco (-2.607) com custo baixo (32k). O enxame não teve cobertura suficiente para encontrar as bacias de atração profundas.
		
		\item \textbf{Enxame Médio (30 - Linha 4):}Melhorou significativamente para -2.987, mas o custo triplicou.
		
		\item \textbf{Enxame Grande (50 - Linha 6):} Aqui temos um salto de qualidade. O valor caiu para -3.308,26 (o melhor valor de toda a tabela).
		
		\item \textbf{Enxame Muito Grande (100 - Linha 7):} Aqui ocorre o fenômeno de ineficiência. O custo foi exorbitante (345k cálculos), mas o resultado (-3.148) foi pior que o enxame de 50.
	\end{itemize}
	
	\item \textbf{Coeficientes de Aceleração}:
	\begin{itemize}
		\item \textbf{Individualista}: A configuração com $c_1=3.5$ (Cognitivo Alto) e $c_2=0.5$ (Social Baixo) obteve o melhor resultado absoluto do grupo de 30 partículas (-3.307,46). Isso sugere que, para a função trabalhada (que é complexa e cheia de mínimos locais), é mais vantajoso deixar as partículas explorarem suas próprias descobertas (memória individual) do que seguir cegamente o líder. A alta autonomia evitou a convergência prematura.
		
		\item \textbf{O Padrão e Social (Linhas 4 e 3):} O padrão ($2/2$) e o Social Forte ($0.5/3.5$) tiveram desempenhos praticamente idênticos e inferiores (-2.987). Isso indica que "seguir o líder" ($c_2$ alto ou médio) tende a prender o enxame em mínimos locais em torno de -2.900, impedindo-os de alcançar o nível de -3.300.
		
	\end{itemize} 
\end{enumerate}

\hspace{4ex}A análise da Tabela 2 demonstra que o algoritmo PSO beneficiou-se fortemente de um comportamento mais 'individualista' para a função $W_{29} + W_1$. A configuração com 30 partículas e ênfase no componente cognitivo ($c_1=3.5, c_2=0.5$) atingiu um valor de aptidão (-3.307) comparável ao obtido pelo enxame de 50 partículas (-3.308), porém com uma redução de aproximadamente 48\% no custo computacional (95 mil cálculos contra 183 mil).

Adicionalmente, observou-se que o aumento excessivo do enxame (100 partículas) resultou em degradação de desempenho (-3.148) e custo proibitivo, sugerindo dificuldades de coordenação ou convergência prematura em um espaço de busca saturado. O enxame pequeno (10 partículas) mostrou-se incapaz de explorar adequadamente o domínio, estagnando em mínimos locais inferiores.

\subsection{Comparação de Desempenho: AG vs. PSO}

\hspace{4ex}Confrontando os resultados obtidos pelos dois algoritmos na minimização da função $W_{29} + W_1$. A comparação baseia-se nas melhores configurações identificadas nas etapas anteriores, ou seja, a configuração que trouxe o melhor custo beneficio: Algoritmo Genético (AG) com população de 50 indivíduos ($Mut=5\%, Cruz=70\%$) e o PSO com enxame de 30 partículas e perfil individualista ($c_1=3.5, c_2=0.5$).

\subsubsection{Qualidade da Solução}
\hspace{4ex}Em termos absolutos, levando em consideração apenas o menor valor que o algoritmo encontrou, o PSO conseguiu se sair melhor. O menor valor  encontrado para a função foi de $-3.307,46$ enquanto que o menor valor encontrado pelo AG foi de $-3.135,21$

\subsubsection{Eficiência Computacional}

\hspace{4ex}Ao analisar o esforço necessário para atingir tais resultados, o cenário se inverte, revelando um \textit{trade-off} importante:

\begin{itemize}
	\item \textbf{Eficiência do AG:} O AG configurado com 50 indivíduos atingiu um resultado muito competitivo (-3.135) consumindo apenas 37.015 cálculos.
	
	\item \textbf{Custo do PSO:} Para superar o AG e atingir a faixa de -3.300, o PSO (configuração individualista) necessitou de 95.082 cálculos.
\end{itemize}
Isso indica que o Algoritmo Genético foi aproximadamente 2,5 vezes mais eficiente em termos de operações por nível de qualidade. O PSO exigiu um esforço computacional desproporcionalmente maior para obter um ganho marginal de precisão (cerca de 5\% melhor no valor da função).

\subsubsection{Sensibilidade e Convergência}

A análise das tabelas revela comportamentos distintos de robustez:

\begin{itemize}
	\item \textbf{Dependência de Parâmetros:} O PSO mostrou-se altamente sensível à calibração dos coeficientes de aceleração. A configuração padrão ($c_1=2, c_2=2$) com 30 partículas estagnou em -2.987, enquanto o ajuste para $c_1=3.5$ desbloqueou o potencial do algoritmo para -3.307. Já o AG mostrou-se mais estável; as variações de mutação (0,05 vs 0,2) e cruzamento mantiveram os resultados numa faixa consistente (-3.135 a -3.180).
	
	\item \textbf{Velocidade de Convergência:} O AG tendeu a convergir mais cedo em termos de gerações (média de 38 a 48 gerações para as melhores configurações). O PSO, devido à inércia dinâmica, manteve a busca ativa por mais tempo, convergindo tipicamente entre as iterações 78 e 95.
\end{itemize}


\newpage

%%%%%%%%%% CONCLUSÃO %%%%%%%%%%%%%%%

\thispagestyle{main}

\section{CONCLUSÃO}


\hspace{4ex}O presente trabalho cumpriu o objetivo de implementar e analisar comparativamente o Algoritmo Genético (AG) e a Otimização por Enxame de Partículas (PSO) na minimização da função objetivo complexa $W_{29} + W_1$. Através de uma metodologia experimental rigorosa, baseada em múltiplas execuções e contagem de operações aritméticas, foi possível traçar o perfil de desempenho de cada técnica.

Em relação ao Algoritmo Genético, conclui-se que o tamanho da população é o fator determinante para o equilíbrio entre custo e qualidade. A configuração com 50 indivíduos (com taxa de cruzamento de 70\% e mutação de 5\%) revelou-se o "ponto ótimo" de eficiência1, atingindo uma solução de alta qualidade (-3.135) com baixo custo computacional. Observou-se que o aumento da população para 100 ou 200 indivíduos gera retornos decrescentes, onde o custo computacional cresce exponencialmente para ganhos marginais na precisão da solução.

Quanto ao Enxame de Partículas (PSO), os resultados demonstraram uma forte sensibilidade aos parâmetros comportamentais. A configuração padrão equilibrada ($C_1=2, C_2=2$) mostrou-se propensa à estagnação em mínimos locais para esta função específica. A descoberta mais relevante foi a superioridade do perfil "Individualista" ($C_1=3.5, C_2=0.5$), que permitiu ao enxame explorar o espaço de busca com maior autonomia, evitando a convergência prematura e atingindo o melhor valor absoluto encontrado em todo o estudo (-3.307).

No confronto direto entre as duas abordagens, evidencia-se um claro \textit{trade-off}:

\begin{enumerate}
	\item \textbf{Qualidade Absoluta:} O PSO foi superior, sendo o único capaz de romper a barreira de -3.300 na minimização da função, demonstrando maior capacidade de refinamento fino (\textit{exploitation}) nas etapas finais da busca.
	
	\item \textbf{Eficiência Computacional:} O AG destacou-se pela eficiência. Para encontrar uma solução competitiva (-3.135), o AG necessitou de apenas 37.015 cálculos, enquanto o PSO exigiu 95.082 cálculos para superar esse resultado. Isso torna o AG aproximadamente 2,5 vezes mais eficiente em termos de processamento por nível de qualidade.
\end{enumerate}


Portanto, para a função $W_{29} + W_1$, a recomendação final depende da prioridade do projeto: se o objetivo for a precisão máxima, recomenda-se o PSO com perfil cognitivo alto; se a prioridade for a economia de recursos computacionais com resultados satisfatórios, o Algoritmo Genético é a escolha mais adequada.

\newpage

%%%%%%%% REFERÊNCIAS (MÉTODO MANUAL) %%%%%%%%%%%%%%%%%

% Adiciona ao Sumário
\addcontentsline{toc}{chapter}{Referências bibliográficas}

% O número {99} indica a largura máxima do rótulo da referência
\begin{thebibliography}{99}
	
	% 1. Holland (1975)
	\bibitem{holland1975adaptation}
	HOLLAND, John H. \textit{Adaptation in Natural and Artificial Systems}. Ann Arbor: University of Michigan Press, 1975.
	
	% 2. Goldberg (1989)
	\bibitem{goldberg1989genetic}
	GOLDBERG, David E. \textit{Genetic Algorithms in Search, Optimization, and Machine Learning}. Reading: Addison-Wesley, 1989.
	
	% 3. Kennedy & Eberhart (1995)
	\bibitem{kennedy1995particle}
	KENNEDY, James; EBERHART, Russell. Particle Swarm Optimization. In: \textit{Proceedings of ICNN'95 - International Conference on Neural Networks}. Perth: IEEE, 1995. v. 4, p. 1942--1948.
	
	% 4. Shi & Eberhart (1998)
	\bibitem{shi1998modified}
	SHI, Yuhui; EBERHART, Russell. A modified particle swarm optimizer. In: \textit{1998 IEEE International Conference on Evolutionary Computation Proceedings}. Anchorage: IEEE, 1998. p. 69--73.
	
	% 5. Herrera et al. (1998)
	\bibitem{herrera1998tackling}
	HERRERA, Francisco; LOZANO, Manuel; VERDEGAY, Jose L. Tackling real-coded genetic algorithms: Operators and tools for behavioural analysis. \textit{Artificial Intelligence Review}, v. 12, n. 4, p. 265--319, 1998.
	
\end{thebibliography}

\appendix
% ... seus apêndices continuam aqui ...
\appendix


\end{document}